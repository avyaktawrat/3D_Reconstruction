{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week1_T2a.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1c2yhO47kmut4jlhYVohxm7nsc0xXx5XF",
      "authorship_tag": "ABX9TyNk9cl4Dm17GPZj9Uh9f49y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyaktawrat/3D_Reconstruction/blob/master/Week1_T2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3r6jYs3_r3j",
        "colab_type": "text"
      },
      "source": [
        "The following links a CNN that has been implemented using Caffe, Your task to implement the same network using Pytorch:\n",
        "\n",
        "(a)  https://kushalvyas.github.io/caffe_cnn.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKZlfbPy_iDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b59e845b-6dea-4c96-ac2b-edba0a0d17a0",
        "id": "kBGvZbOdJaqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "class SubclassModel(nn.Module): \n",
        "  def __init__(self): \n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels= 3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "    ## the result on each output channel is calculated from the convolution kernel \n",
        "    ## corresponding to that output channel and takes input from all channels in the input array\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=  96, out_channels= 256, kernel_size= 5, stride= 1, padding= 2)\n",
        "    self.conv3 = nn.Conv2d(in_channels= 256, out_channels= 384, kernel_size= 3, stride= 1, padding= 1)\n",
        "    self.conv4 = nn.Conv2d(in_channels= 384, out_channels= 384, kernel_size= 5, stride= 1, padding= 2)\n",
        "    self.conv5 = nn.Conv2d(in_channels= 384, out_channels= 256, kernel_size= 5, stride= 1, padding= 2)\n",
        "\n",
        "    self.activation = nn.ReLU()\n",
        "    self.norm = nn.LocalResponseNorm(size=2)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 3,stride = 2,padding = 0)\n",
        "\n",
        "    # self.re = t.reshape(1, -1)        ## for reshaping the tensor for input to linear\n",
        "    # t = t.squeeze()\n",
        "\n",
        "    self.fc6 = nn.Linear(256,4096)           \n",
        "    self.fc7 = nn.Linear(4096,4096)\n",
        "    self.fc8 = nn.Linear(4096,1000)\n",
        "    self.fc9 = nn.Linear(1000,2)\n",
        "    \n",
        "    self.prob = nn.Softmax(dim = 1)                  ############\n",
        "    self.drop = nn.Dropout()\n",
        "\n",
        "\n",
        "  def forward(self, input): \n",
        "    # print(input.size())\n",
        "    conv_1 = self.conv1(input)              ## 3 X 96 X 96 --> 96 X 22 X 22\n",
        "    activated_1 = self.activation(conv_1)   \n",
        "    pool_1 = self.pool(activated_1)         ## --> 96 X 10 X 10\n",
        "    norm_1 = self.norm(pool_1)\n",
        "\n",
        "    conv_2 = self.conv2(norm_1)             ## --> 256 X 10 X 10\n",
        "    activated_2 = self.activation(conv_2)\n",
        "    pool_2 = self.pool(activated_2)         ## --> 256 X 4 X 4\n",
        "    norm_2 = self.norm(pool_2)\n",
        "\n",
        "    conv_3 = self.conv3(norm_2)             ## --> 384 X 4 X 4\n",
        "    activated_3 = self.activation(conv_3)\n",
        "\n",
        "    conv_4 = self.conv4(activated_3)        ## --> 384 X 4 X 4\n",
        "    activated_4 = self.activation(conv_4)\n",
        "\n",
        "    conv_5 = self.conv5(activated_4)        ## --> 256 X 4 X 4\n",
        "    activated_5 = self.activation(conv_5)\n",
        "    pool_5 = self.pool(activated_5)         ## --> 256 X 1 X 1\n",
        "    \n",
        "    pool_5 = (pool_5.view(pool_5.size(0),-1))\n",
        "    # print(pool_5.size())\n",
        "\n",
        "    fc_6 = self.fc6(pool_5)\n",
        "    drop_6 = self.drop(fc_6)\n",
        "    activated_6 = self.activation(drop_6)\n",
        "\n",
        "    fc_7 = self.fc7(activated_6)\n",
        "    drop_7 = self.drop(fc_7)\n",
        "    activated_7 = self.activation(drop_7)\n",
        "\n",
        "    fc_8 = self.fc8(activated_7)\n",
        "    fc_9 = self.fc9(fc_8)\n",
        "\n",
        "    output = self.prob(fc_9)\n",
        "    return output\n",
        "AlexNET = SubclassModel() \n",
        "AlexNET\n",
        "\n",
        "#output = (input - kernel_size) / stride + 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SubclassModel(\n",
              "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv5): Conv2d(384, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (activation): ReLU()\n",
              "  (norm): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
              "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc6): Linear(in_features=256, out_features=4096, bias=True)\n",
              "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc8): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (fc9): Linear(in_features=1000, out_features=2, bias=True)\n",
              "  (prob): Softmax(dim=1)\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7D4mg9Kso3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outputSize(in_size, kernel_size, stride, padding):  ## in size is spatial dimension, not channel\n",
        "  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
        "  return(output)\n",
        "def poolSize(Input, Pool, Stride, Padding):\n",
        "  output = int((Input - Pool + 2*Padding)/Stride) + 1\n",
        "  return(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSF_R8KNbWOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(outputSize(96, 11, 4, 0))\n",
        "# print(poolSize(22, 3, 2, 0))\n",
        "\n",
        "# print(outputSize(10, 5, 1, 2))\n",
        "# print(poolSize(10, 3, 2, 0))\n",
        "\n",
        "# print(outputSize(4, 3, 1, 1))\n",
        "\n",
        "# print(outputSize(4, 5, 1, 2))\n",
        "\n",
        "# print(outputSize(4, 5, 1, 2))\n",
        "# print(poolSize(4, 3, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17q7-8i6OgzE",
        "colab_type": "text"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4AU6lN-kKBh",
        "colab_type": "code",
        "outputId": "86e120f9-33e4-4921-9a0a-504a2abfb7ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "dataset, pcam_info = tfds.load(\"patch_camelyon\", with_info=True, split=['train','test'], shuffle_files=True)\n",
        "print(pcam_info)  \n",
        "\n",
        "# print(dataset)\n",
        "# (img_train, label_train), (img_test, label_test) = tfds.as_numpy(dataset)\n",
        "train, test = tfds.as_numpy(dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='patch_camelyon',\n",
            "    version=2.0.0,\n",
            "    description='The PatchCamelyon benchmark is a new and challenging image classification\n",
            "dataset. It consists of 327.680 color images (96 x 96px) extracted from\n",
            "histopathologic scans of lymph node sections. Each image is annoted with a\n",
            "binary label indicating presence of metastatic tissue. PCam provides a new\n",
            "benchmark for machine learning models: bigger than CIFAR10, smaller than\n",
            "Imagenet, trainable on a single GPU.\n",
            "',\n",
            "    homepage='https://patchcamelyon.grand-challenge.org/',\n",
            "    features=FeaturesDict({\n",
            "        'id': Text(shape=(), dtype=tf.string),\n",
            "        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    }),\n",
            "    total_num_examples=327680,\n",
            "    splits={\n",
            "        'test': 32768,\n",
            "        'train': 262144,\n",
            "        'validation': 32768,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@misc{b_s_veeling_j_linmans_j_winkens_t_cohen_2018_2546921,\n",
            "      author       = {B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling},\n",
            "      title        = {Rotation Equivariant CNNs for Digital Pathology},\n",
            "      month        = sep,\n",
            "      year         = 2018,\n",
            "      doi          = {10.1007/978-3-030-00934-2_24},\n",
            "      url          = {https://doi.org/10.1007/978-3-030-00934-2_24}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBomwjuBkToO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f1b02eaf-4598-4c22-c958-06d53e9f200d"
      },
      "source": [
        "k = 0\n",
        "for i in train:\n",
        "  # `{'image': np.array(shape=(96,96,3)), 'labels': np.array(shape=())}`\n",
        "  \n",
        " \n",
        "  i['image'] = torch.from_numpy(i['image'])\n",
        "  i['image'] = ((i['image'].transpose(0,2)).float()/255).unsqueeze(0)\n",
        "\n",
        "  i['label'] = torch.from_numpy(np.array(i['label']))\n",
        "  i['label'] = ((i['label']).unsqueeze(0)).unsqueeze(0)\n",
        "\n",
        "  i['label'] = torch.zeros(i['label'].size(0),2).scatter_(1, i['label'], 1.0)\n",
        "\n",
        "\n",
        "  if k == 0:\n",
        "    X_train = i['image']\n",
        "    y_train = i['label']\n",
        "  else:\n",
        "    X_train = torch.cat([X_train, i['image']], dim = 0)\n",
        "    # print(i['image'])\n",
        "    # print(i['image'].size())\n",
        "\n",
        "  \n",
        "    y_train = torch.cat([y_train, i['label']], dim = 0)\n",
        "  if k == 5000:\n",
        "    break\n",
        "\n",
        "  k = k + 1\n",
        "\n",
        "# print (y_train)\n",
        "print(X_train.size())\n",
        "\n",
        "\n",
        "\n",
        "###############################\n",
        "k = 0\n",
        "for i in test:\n",
        "  # `{'image': np.array(shape=(96,96,3)), 'labels': np.array(shape=())}`\n",
        "  \n",
        "\n",
        "  i['image'] = torch.from_numpy(i['image'])\n",
        "\n",
        "  i['image'] = ((i['image'].transpose(0,2)).float()/255).unsqueeze(0)\n",
        "\n",
        "  i['label'] = torch.from_numpy(np.array(i['label']))\n",
        "  i['label'] = ((i['label']).unsqueeze(0)).unsqueeze(0)\n",
        "\n",
        "\n",
        "  i['label'] = torch.zeros(i['label'].size(0),2).scatter_(1, i['label'], 1.0)\n",
        "\n",
        "  if k == 0:\n",
        "    X_test = i['image']\n",
        "    y_test = i['label']\n",
        "    \n",
        "  else:\n",
        "    X_test = torch.cat([X_test, i['image']], dim = 0)\n",
        "    # print(i['image'])\n",
        "    # print(i['image'].size())\n",
        "\n",
        "  \n",
        "    y_test = torch.cat([y_test, i['label']], dim = 0)\n",
        "  if k == 1000:\n",
        "    break\n",
        "\n",
        "  k = k + 1\n",
        "\n",
        "# print (y_test)\n",
        "print(X_test.size())\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5001, 3, 96, 96])\n",
            "torch.Size([1001, 3, 96, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VpjIOgzKGd5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8622b98b-450c-4dbb-af2e-1fbcf0c9d90c"
      },
      "source": [
        "print(y_test.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1001, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZiFSheIS5Cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2f37df10-534e-4110-9a62-591fdbc8f235"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        ...,\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNNIQqAFbtE",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjbyXeELHqa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_model(n_epochs, optimizer, model, loss_fn, X_train, y_train, X_test, y_test):\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    y_pred_train = model(X_train)\n",
        "    loss_train = loss_fn(y_pred_train, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()  ### updates all parameters\n",
        "    # print(epoch)\n",
        "    \n",
        "    if epoch % 2 ==0 :\n",
        "      y_pred_test = model(X_test)\n",
        "      loss_test = loss_fn(y_pred_test, y_test)\n",
        "      \n",
        "      correct = ((y_pred_test.int() == y_test.int()).sum(dim = 0)[0]).float()\n",
        "      total = y_test.size(0)\n",
        "      # print(y_pred_test.size())\n",
        "      # print(y_pred_train)\n",
        "      # print(y_test)\n",
        "      print('Epoch {}, Training loss {}, Testing loss {}'.format( epoch, float(loss_train), float(loss_test)))\n",
        "      print('Test Accuracy of the model on the test images: {} %'.format((correct / total) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLhjnb7sLLQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDqjywl3CHhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "58bad9e7-6464-4186-85a8-60729668a774"
      },
      "source": [
        "optimizer = optim.SGD(AlexNET.parameters(),lr = 0.1)\n",
        "\n",
        "training_model(n, optimizer, AlexNET, loss_func, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, Training loss 0.2500792443752289, Testing loss 0.2503412961959839\n",
            "Test Accuracy of the model on the test images: 48.4515495300293 %\n",
            "Epoch 4, Training loss 0.2500774562358856, Testing loss 0.25031450390815735\n",
            "Test Accuracy of the model on the test images: 48.4515495300293 %\n",
            "Epoch 6, Training loss 0.2500230371952057, Testing loss 0.25026735663414\n",
            "Test Accuracy of the model on the test images: 48.4515495300293 %\n",
            "Epoch 8, Training loss 0.250024676322937, Testing loss 0.2502555251121521\n",
            "Test Accuracy of the model on the test images: 48.4515495300293 %\n",
            "Epoch 10, Training loss 0.25002896785736084, Testing loss 0.25010743737220764\n",
            "Test Accuracy of the model on the test images: 48.4515495300293 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
