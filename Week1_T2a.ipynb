{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week1_T2a.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz4986DqF+LCD29KyMCCqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyaktawrat/3D_Reconstruction/blob/master/Week1_T2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3r6jYs3_r3j",
        "colab_type": "text"
      },
      "source": [
        "The following links a CNN that has been implemented using Caffe, Your task to implement the same network using Pytorch:\n",
        "\n",
        "(a)  https://kushalvyas.github.io/caffe_cnn.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKZlfbPy_iDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n44-wvc6Rrd9",
        "colab_type": "code",
        "outputId": "47e0dbad-42e4-46f1-b224-4e1a3898891b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "class SubclassModel(nn.Module): \n",
        "  def __init__(self,num_classes): \n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels= 3, out_channels=96, kernel_size=11, stride=4, padding=0)\n",
        "    ## the result on each output channel is calculated from the convolution kernel \n",
        "    ## corresponding to that output channel and takes input from all channels in the input array\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=  96, out_channels= 256, kernel_size= 5, stride= 1, padding= 2)\n",
        "    self.conv3 = nn.Conv2d(in_channels= 256, out_channels= 384, kernel_size= 3, stride= 1, padding= 1)\n",
        "    self.conv4 = nn.Conv2d(in_channels= 384, out_channels= 384, kernel_size= 5, stride= 1, padding= 2)\n",
        "    self.conv5 = nn.Conv2d(in_channels= 384, out_channels= 256, kernel_size= 5, stride= 1, padding= 2)\n",
        "\n",
        "    self.activation = nn.ReLU()\n",
        "    self.norm = nn.LocalResponseNorm(size=2)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 3,stride = 2,padding = 0)\n",
        "\n",
        "    self.fc6 = nn.Linear(256,4096)           \n",
        "    self.fc7 = nn.Linear(4096,4096)\n",
        "    self.fc8 = nn.Linear(4096,1000)\n",
        "    \n",
        "    self.prob = nn.Softmax()                  ############\n",
        "    self.drop = nn.Dropout()\n",
        "\n",
        "\n",
        "  def forward(self, input): \n",
        "    conv_1 = self.conv1(input)              ## 3 X 96 X 96 --> 96 X 22 X 22\n",
        "    activated_1 = self.activation(conv_1)   \n",
        "    pool_1 = self.pool(activated_1)         ## --> 96 X 10 X 10\n",
        "    norm_1 = self.norm(pool_1)\n",
        "\n",
        "    conv_2 = self.conv2(norm_1)             ## --> 256 X 10 X 10\n",
        "    activated_2 = self.activation(conv_2)\n",
        "    pool_2 = self.pool(activated_2)         ## --> 256 X 4 X 4\n",
        "    norm_2 = self.norm(pool_2)\n",
        "\n",
        "    conv_3 = self.conv3(norm_2)             ## --> 384 X 4 X 4\n",
        "    activated_3 = self.activation(conv_3)\n",
        "\n",
        "    conv_4 = self.conv4(activated_3)        ## --> 384 X 4 X 4\n",
        "    activated_4 = self.activation(conv_4)\n",
        "\n",
        "    conv_5 = self.conv5(activated_4)        ## --> 256 X 4 X 4\n",
        "    activated_5 = self.activation(conv_5)\n",
        "    pool_5 = self.pool(activated_5)         ## --> 256 X 1 X 1\n",
        "    \n",
        "    fc_6 = self.fc6(pool_5)\n",
        "    drop_6 = self.drop(fc_6)\n",
        "    activated_6 = self.activated(drop_6)\n",
        "\n",
        "    fc_7 = self.fc7(activated_6)\n",
        "    drop_7 = self.drop(fc_7)\n",
        "    activated_7 = self.activated(drop_7)\n",
        "\n",
        "    fc_8 = self.fc8(activated_7)\n",
        "\n",
        "    output = self.prob(fc_8,dim=1)\n",
        "    return output\n",
        "AlexNET = SubclassModel(2) \n",
        "AlexNET\n",
        "\n",
        "#output = (input - kernel_size) / stride + 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SubclassModel(\n",
              "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (conv5): Conv2d(384, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (activation): ReLU()\n",
              "  (norm): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
              "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc6): Linear(in_features=256, out_features=4096, bias=True)\n",
              "  (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (fc8): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  (prob): Softmax(dim=None)\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7D4mg9Kso3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outputSize(in_size, kernel_size, stride, padding):  ## in size is spatial dimension, not channel\n",
        "  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
        "  return(output)\n",
        "def poolSize(Input, Pool, Stride, Padding):\n",
        "  output = int((Input - Pool + 2*Padding)/Stride) + 1\n",
        "  return(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSF_R8KNbWOw",
        "colab_type": "code",
        "outputId": "065ea173-9b90-4c22-969f-1190bad5ee34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(outputSize(96, 11, 4, 0))\n",
        "print(poolSize(22, 3, 2, 0))\n",
        "\n",
        "print(outputSize(10, 5, 1, 2))\n",
        "print(poolSize(10, 3, 2, 0))\n",
        "\n",
        "print(outputSize(4, 3, 1, 1))\n",
        "\n",
        "print(outputSize(4, 5, 1, 2))\n",
        "\n",
        "print(outputSize(4, 5, 1, 2))\n",
        "print(poolSize(4, 3, 2, 0))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "10\n",
            "10\n",
            "4\n",
            "4\n",
            "4\n",
            "4\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17q7-8i6OgzE",
        "colab_type": "text"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4AU6lN-kKBh",
        "colab_type": "code",
        "outputId": "80c6b9bd-fc1b-47dc-d34b-42c90230b7c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "dataset, pcam_info = tfds.load(\"patch_camelyon\", with_info=True, split=['train','test'], shuffle_files=True)\n",
        "print(pcam_info)  \n",
        "\n",
        "# print(dataset)\n",
        "# (img_train, label_train), (img_test, label_test) = tfds.as_numpy(dataset)\n",
        "train, test = tfds.as_numpy(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='patch_camelyon',\n",
            "    version=2.0.0,\n",
            "    description='The PatchCamelyon benchmark is a new and challenging image classification\n",
            "dataset. It consists of 327.680 color images (96 x 96px) extracted from\n",
            "histopathologic scans of lymph node sections. Each image is annoted with a\n",
            "binary label indicating presence of metastatic tissue. PCam provides a new\n",
            "benchmark for machine learning models: bigger than CIFAR10, smaller than\n",
            "Imagenet, trainable on a single GPU.\n",
            "',\n",
            "    homepage='https://patchcamelyon.grand-challenge.org/',\n",
            "    features=FeaturesDict({\n",
            "        'id': Text(shape=(), dtype=tf.string),\n",
            "        'image': Image(shape=(96, 96, 3), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "    }),\n",
            "    total_num_examples=327680,\n",
            "    splits={\n",
            "        'test': 32768,\n",
            "        'train': 262144,\n",
            "        'validation': 32768,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@misc{b_s_veeling_j_linmans_j_winkens_t_cohen_2018_2546921,\n",
            "      author       = {B. S. Veeling, J. Linmans, J. Winkens, T. Cohen, M. Welling},\n",
            "      title        = {Rotation Equivariant CNNs for Digital Pathology},\n",
            "      month        = sep,\n",
            "      year         = 2018,\n",
            "      doi          = {10.1007/978-3-030-00934-2_24},\n",
            "      url          = {https://doi.org/10.1007/978-3-030-00934-2_24}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBomwjuBkToO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0f1443b9-791f-4470-90fa-7782ced145fe"
      },
      "source": [
        "k = 0\n",
        "for i in train:\n",
        "  # `{'image': np.array(shape=(96,96,3)), 'labels': np.array(shape=())}`\n",
        "  \n",
        " \n",
        "  i['image'] = torch.from_numpy(i['image'])\n",
        "  i['image'] = (i['image'].transpose(0,2)).unsqueeze(0)\n",
        "\n",
        "  i['label'] = torch.from_numpy(np.array(i['label']))\n",
        "  i['label'] = (i['label']).unsqueeze(0)\n",
        "\n",
        "  if k == 0:\n",
        "    X_train = i['image']\n",
        "    y_train = i['label']\n",
        "  else:\n",
        "    X_train = torch.cat([X_train, i['image']], dim = 0)\n",
        "    # print(i['image'])\n",
        "    # print(i['image'].size())\n",
        "\n",
        "  \n",
        "    y_train = torch.cat([y_train, i['label']], dim = 0)\n",
        "  if k == 1000:\n",
        "    break\n",
        "\n",
        "  k = k + 1\n",
        "\n",
        "# print (y_train)\n",
        "print(X_train.size())\n",
        "\n",
        "\n",
        "\n",
        "###############################\n",
        "k = 0\n",
        "for i in test:\n",
        "  # `{'image': np.array(shape=(96,96,3)), 'labels': np.array(shape=())}`\n",
        "  \n",
        " \n",
        "  i['image'] = torch.from_numpy(i['image'])\n",
        "  i['image'] = (i['image'].transpose(0,2)).unsqueeze(0)\n",
        "\n",
        "  i['label'] = torch.from_numpy(np.array(i['label']))\n",
        "  i['label'] = (i['label']).unsqueeze(0)\n",
        "\n",
        "  if k == 0:\n",
        "    X_test = i['image']\n",
        "    y_test = i['label']\n",
        "  else:\n",
        "    X_test = torch.cat([X_test, i['image']], dim = 0)\n",
        "    # print(i['image'])\n",
        "    # print(i['image'].size())\n",
        "\n",
        "  \n",
        "    y_test = torch.cat([y_test, i['label']], dim = 0)\n",
        "  if k == 100:\n",
        "    break\n",
        "\n",
        "  k = k + 1\n",
        "\n",
        "# print (y_test)\n",
        "print(X_test.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1001, 3, 96, 96])\n",
            "torch.Size([101, 3, 96, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbNNIQqAFbtE",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjbyXeELHqa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_model(n_epochs, optimizer, model, loss_fn, X_train, y_train, X_test, y_test):\n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    y_pred_train = model(X_train)\n",
        "    loss_train = loss_fn(y_pred_train, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()  ### updates all parameters\n",
        "\n",
        "    if epoch == 1 or epoch % 1000 ==0 :\n",
        "      y_pred_test = model(X_test)\n",
        "      loss_test = loss_fn(y_pred_test, y_test)\n",
        "      \n",
        "      correct = (y_pred_test == y_test).sum(dim = 0)\n",
        "      total = y_test.size(0)\n",
        "      print('Epoch {}, Training loss {}, Validation loss {}'.format( epoch, float(loss_train), float(loss_val)))\n",
        "      print('Test Accuracy of the model on the test images: {} %'.format((correct / total) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLhjnb7sLLQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 1000\n",
        "\n",
        "loss_func = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDqjywl3CHhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(AlexNET.parameters(),lr = 1e-2)\n",
        "\n",
        "# training_model(n, optimizer, AlexNET, loss_func, X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}